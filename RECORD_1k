### 0.778954802259887
  def createModel(self):
    input_text = Input(shape=(1,), dtype='string')
    embedding = Lambda(self.use_embedding, output_shape=(512,))(input_text)
    dense = Dense(512, activation='relu')(
        embedding)  #kernel_regularizer=l1(0.0001) #
    dense = Dropout(0.4)(dense)
    pred = Dense(self.n_labels, activation='softmax')(dense)
    self.model = Model(inputs=[input_text], outputs=pred)
    self.model.compile(loss='categorical_crossentropy',
                       optimizer='adam',
                       metrics=['accuracy'])
    print(self.model.summary())

### 0.7838983050847458
  def createModel(self):
    input_text = Input(shape=(1,), dtype='string')
    embedding = Lambda(self.use_embedding, output_shape=(512,))(input_text)
    dense = Dense(512)(embedding)  #kernel_regularizer=l1(0.0001) #
    dense = BatchNormalization()(dense)
    dense = RELU()(dense)
    dense = Dropout(0.4)(dense)
    pred = Dense(self.n_labels, activation='softmax')(dense)
    self.model = Model(inputs=[input_text], outputs=pred)
    self.model.compile(loss='categorical_crossentropy',
                       optimizer='adam',
                       metrics=['accuracy'])
    print(self.model.summary()) 

### 
  def createModel(self):
    input_text = Input(shape=(1,), dtype='string')
    embedding = Lambda(self.use_embedding, output_shape=(512,))(input_text)
    dense = Dense(512)(embedding)  #kernel_regularizer=l1(0.0001) #
    dense = LayerNormalization()(dense)
    dense = ReLU()(dense)
    dense = Dropout(0.4)(dense)
    pred = Dense(self.n_labels, activation='softmax')(dense)
    self.model = Model(inputs=[input_text], outputs=pred)
    self.model.compile(loss='categorical_crossentropy',
                       optimizer='adam',
                       metrics=['accuracy'])
    print(self.model.summary())       